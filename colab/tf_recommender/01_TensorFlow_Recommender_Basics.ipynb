{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_TensorFlow_Recommender_Basics.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "45_plgpxQ3nC"
      ],
      "authorship_tag": "ABX9TyNmakx15NxBeh09IniZizfV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinTheRainmaker/Recommendation_Algorithms/blob/main/colab/tf_recommender/01_TensorFlow_Recommender_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %tensorflow_version 2.x\n",
        "# import tensorflow as tf\n",
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   raise SystemError('GPU device not found')\n",
        "# print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "GAoxVyeY8ud9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommending Movies"
      ],
      "metadata": {
        "id": "hXalgd4aMhZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Real-world의 Recommender는 두 단계로 이루어지곤 한다.\n",
        "1. The Retrieval Stage:\n",
        "\n",
        "  전체 후보군으로부터 초기 후보군을 골라내는 단계. 유저가 관심을 가지지 않을 후보를 제거함으로써 계산에 효율성을 더한다.\n",
        "\n",
        "2. The Ranking Stage:\n",
        "\n",
        "  Retrieval model의 결과를 인풋으로 받아 fine-tuning을 통해 최적의 recommendation을 선별하는 단계. Item의 set을 narrow down 시켜 최적 후보군 리스트를 만들어낸다.\n"
      ],
      "metadata": {
        "id": "hgMLogp9Nafz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Retrieval Model"
      ],
      "metadata": {
        "id": "45_plgpxQ3nC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieval Model은 두 개의 sub-model로 이루어진다.\n",
        "\n",
        "1. Query feature를 이용해서 Query representation을 계산하는 Query Model\n",
        "2. Candidate feature를 이용해서 Candidate representation을 계산하는 Candidate Model\n",
        "\n",
        "두 모델의 output은 서로 multiple되어 query-candidate affinity score를 출력한다."
      ],
      "metadata": {
        "id": "7yJgZHlsgrPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process"
      ],
      "metadata": {
        "id": "bR_Iw52IXeoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 데이터를 훈련세트와 검증세트로 나눈다.\n",
        "2. Retrieval Model을 Implement\n",
        "3. Fit & Evaluate\n",
        "4. 더 효율적인 서빙을 위해 Approximate Nearest Neighbours (ANN) index를 Build하여 Export"
      ],
      "metadata": {
        "id": "-kQEtm7yYJzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Packages"
      ],
      "metadata": {
        "id": "Sja0GvimZ3C5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go0nvt18MSKY"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install -q scann"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ScaNN (Scalable Nearest Neighbors): 구글이 개발한 ANN 알고리즘 중 하나로, 거의 모든 Queries per seconds에서 가장 최적의 Recall 값을 낸 알고리즘이다."
      ],
      "metadata": {
        "id": "NQz7by_xZ--O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs"
      ],
      "metadata": {
        "id": "HsOA9cFYZ89S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "g_YhxqpAckIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터는 유명한 영화 데이터인 movielens를 사용한다.\n",
        "\n",
        "이 데이터는 다음과 같이 두 가지 방식으로 다뤄질 수 있다.\n",
        "1. Implicit Feedback: 유저가 어떤 영화를 보았는지\n",
        "2. Explicit Feedback: 유저가 본 영화에 대해서 어떤 영화를 얼마나 선호하는지"
      ],
      "metadata": {
        "id": "8Z37ULLKch2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retireval Model을 다루는 파트에서는 Implicit system에 집중하여, 유저가 본 영화는 Positive example로, 보지 않은 영화는 Implicit negative example로 간주하여 진행하도록 하겠다.\n",
        "\n",
        "\\* Implicit Negative Example이란: 보지 않은 영화라고해서 전부 유저가 선호하지 않는 것은 아니다. 이는 Implicit Feedback에서 주로 사용되는 개념으로, Implicit Negative는 실제로 유저가 선호하지 않는 Real Negative와 유저가 미래에 소비할지도 모르는 아이템이지만 아직 소비하지 않은, Missing Value가 혼합되어 있다. "
      ],
      "metadata": {
        "id": "vX_rbfJacqZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings data.\n",
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "# Features of all the available movies.\n",
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
      ],
      "metadata": {
        "id": "YUVWhY5Ia--S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ratings), len(movies))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqULwuZ3kMYC",
        "outputId": "c4670fdb-2c23-45ee-badf-aff2d9a6cc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000 1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in ratings.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ3EMS9SbHeH",
        "outputId": "8c9be575-a9cc-427c-8d4f-534d6ef21aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bucketized_user_age': 45.0,\n",
            " 'movie_genres': array([7]),\n",
            " 'movie_id': b'357',\n",
            " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
            " 'raw_user_age': 46.0,\n",
            " 'timestamp': 879024327,\n",
            " 'user_gender': True,\n",
            " 'user_id': b'138',\n",
            " 'user_occupation_label': 4,\n",
            " 'user_occupation_text': b'doctor',\n",
            " 'user_rating': 4.0,\n",
            " 'user_zip_code': b'53211'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "장르가 integer labels로 encodding되어있음을 알 수 있다."
      ],
      "metadata": {
        "id": "ANs7ndcpcIQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "})\n",
        "movies = movies.map(lambda x: x[\"movie_title\"])"
      ],
      "metadata": {
        "id": "yj9snP31bZDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`user_id`와 `movie_title`만을 남기도록 하자."
      ],
      "metadata": {
        "id": "-0mWh8Q_cPvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit과 Evaluate를 수행하기 위해서는 데이터셋을 훈련세트와 검증세트로 나누어야 한다.\n",
        "\n",
        "실무 환경에서 사용될 Industrial Model에서는 이것이 시간에 기반하여 이루어진다. 즉, 시간 T까지 수집된 데이터는 T 이후의 예측을 수행하기 위해 사용된다.\n",
        "\n",
        "여기서는 이미 수집된 데이터를 이용하는 것이므로, random split 방식을 사용하도록 하겠다."
      ],
      "metadata": {
        "id": "MVqP1uRIdgoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)"
      ],
      "metadata": {
        "id": "YmEn7U2dcGtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# figure out unique user ids and movie titles\n",
        "movie_titles = movies.batch(1_000)\n",
        "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
        "\n",
        "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
        "\n",
        "unique_movie_titles[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVclFrUSed70",
        "outputId": "f7d254f7-d089-431f-9ca5-2c8a2e128af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b\"'Til There Was You (1997)\", b'1-900 (1994)',\n",
              "       b'101 Dalmatians (1996)', b'12 Angry Men (1957)', b'187 (1997)',\n",
              "       b'2 Days in the Valley (1996)',\n",
              "       b'20,000 Leagues Under the Sea (1954)',\n",
              "       b'2001: A Space Odyssey (1968)',\n",
              "       b'3 Ninjas: High Noon At Mega Mountain (1998)',\n",
              "       b'39 Steps, The (1935)'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_user_ids[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKiPPy0osM5u",
        "outputId": "9e848b58-7f81-4ee1-dfa9-86e7a785906a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'1', b'10', b'100', b'101', b'102', b'103', b'104', b'105',\n",
              "       b'106', b'107'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing a Model"
      ],
      "metadata": {
        "id": "nlHFwyRYq3OT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 아키텍처를 선택하는 것은 전체 모델링의 핵심부이다.\n",
        "\n",
        "여기서 우리는 Two-tower Retrieval Model을 구축할 것이고, 각각을 개별적으로 구축한 후 final model로 통합시킬 것이다."
      ],
      "metadata": {
        "id": "xfEm0KuirD6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Query Tower"
      ],
      "metadata": {
        "id": "cgdW8TgErV16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decide the dimensionality of the query and candidate representations\n",
        "embedding_dimension = 32"
      ],
      "metadata": {
        "id": "0z7MSvUmq1lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "값을 높게 잡으면 더욱 정확한 모델이 될 수 있지만, 동시에 학습속도가 느려지고 overfitting의 우려 또한 커진다."
      ],
      "metadata": {
        "id": "-advGAJEr6s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_user_ids, mask_token=None),\n",
        "  # We add an additional embedding to account for unknown tokens.\n",
        "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "])"
      ],
      "metadata": {
        "id": "RbzW7o_driLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Candidate Tower"
      ],
      "metadata": {
        "id": "5SjZo3oZx4z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.StringLookup(\n",
        "      vocabulary=unique_movie_titles, mask_token=None),\n",
        "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
        "])"
      ],
      "metadata": {
        "id": "0RhlQWxrsZB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Metrics"
      ],
      "metadata": {
        "id": "cxMMNEEWx-nZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리의 학습 데이터에는 Positive (유저, 영화)쌍이 포함되어 있다. 여기서 Positive하다는 것은, 실제로 유저가 본 영화가 서로 묶인 쌍이라는 뜻이다.\n",
        "\n",
        "이러한 쌍이 다른 모든 가능한 (유저, 영화)쌍보다 높은 affinity score를 가진다면, 우리의 모델은 정확하다고 할 수 있다.\n",
        "\n",
        "이를 위해 우리는 `tfrs.metrics.FactorizedTopK` metric을 사용할 것이다. 이는 implicit negative로 사용된 후보군 데이터를 인자로 가진다."
      ],
      "metadata": {
        "id": "tqMI5x8ByKL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = tfrs.metrics.FactorizedTopK(\n",
        "  candidates=movies.batch(128).map(movie_model)\n",
        ")"
      ],
      "metadata": {
        "id": "VL7DDMXIx8xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss"
      ],
      "metadata": {
        "id": "5j4Z8UmuzLNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음으로, 우리의 모델을 학습시킬 때 필요한 Lossㄹ르 정의해보자.\n",
        "\n",
        "TFRS는 이를 편리하게 해주는 몇 가지 Loss layer와 tasks를 가지고있다.\n",
        "\n",
        "여기서 우리는 `Retrieval`이라는 task object를 사용할 것이다."
      ],
      "metadata": {
        "id": "4B1Q5JRwzMc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = tfrs.tasks.Retrieval(\n",
        "  metrics=metrics\n",
        ")"
      ],
      "metadata": {
        "id": "nC_vX_j5zKdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 task object는 그 자체로 Keras layer로 동작하며, query embedding과 candidate embedding을 인자로 받아서 loss를 반환한다."
      ],
      "metadata": {
        "id": "BLVw0_0izqEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Full model"
      ],
      "metadata": {
        "id": "fuRmaVw7z15P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFRS는 Base model class인 `tfrs.models.Model`을 제공한다. 이 덕분에 `__init__` 메서드 안에 components를 set up하고 `compute_loss` 메서드를 implement만 하면 된다."
      ],
      "metadata": {
        "id": "q40y0uqJ5IGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MovielensModel(tfrs.Model):\n",
        "\n",
        "  def __init__(self, user_model, movie_model):\n",
        "    super().__init__()\n",
        "    self.movie_model: tf.keras.Model = movie_model\n",
        "    self.user_model: tf.keras.Model = user_model\n",
        "    self.task: tf.keras.layers.Layer = task\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    # And pick out the movie features and pass them into the movie model,\n",
        "    # getting embeddings back.\n",
        "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(user_embeddings, positive_movie_embeddings)"
      ],
      "metadata": {
        "id": "pJjbUWyDzlss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tfrs.Model` base class는 training loss와 test loss를 같은 메서드를 사용해서 계산할 수 있도록 해주는 편리한 class이다.\n",
        "\n",
        "이 외에 `tf.keras.Model`로부터 inherit 받아 `train_step`과 `test_step`을 오버라이딩 시켜 같은 기능을 구현할 수도 있다."
      ],
      "metadata": {
        "id": "viUsetcq6M3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NoBaseClassMovielensModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, user_model, movie_model):\n",
        "    super().__init__()\n",
        "    self.movie_model: tf.keras.Model = movie_model\n",
        "    self.user_model: tf.keras.Model = user_model\n",
        "    self.task: tf.keras.layers.Layer = task\n",
        "\n",
        "  def train_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "\n",
        "    # Set up a gradient tape to record gradients.\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # Loss computation.\n",
        "      user_embeddings = self.user_model(features[\"user_id\"])\n",
        "      positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "      loss = self.task(user_embeddings, positive_movie_embeddings)\n",
        "\n",
        "      # Handle regularization losses as well.\n",
        "      regularization_loss = sum(self.losses)\n",
        "\n",
        "      total_loss = loss + regularization_loss\n",
        "\n",
        "    gradients = tape.gradient(total_loss, self.trainable_variables)\n",
        "    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "    metrics = {metric.name: metric.result() for metric in self.metrics}\n",
        "    metrics[\"loss\"] = loss\n",
        "    metrics[\"regularization_loss\"] = regularization_loss\n",
        "    metrics[\"total_loss\"] = total_loss\n",
        "\n",
        "    return metrics\n",
        "\n",
        "  def test_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "\n",
        "    # Loss computation.\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "    loss = self.task(user_embeddings, positive_movie_embeddings)\n",
        "\n",
        "    # Handle regularization losses as well.\n",
        "    regularization_loss = sum(self.losses)\n",
        "\n",
        "    total_loss = loss + regularization_loss\n",
        "\n",
        "    metrics = {metric.name: metric.result() for metric in self.metrics}\n",
        "    metrics[\"loss\"] = loss\n",
        "    metrics[\"regularization_loss\"] = regularization_loss\n",
        "    metrics[\"total_loss\"] = total_loss\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "aaNZ_T3v5vJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서는 모델링에 집중하고 보일러 플레이트(boilerplate)로부터 벗어나기 위해 `tfrs.Model`을 사용하겠다."
      ],
      "metadata": {
        "id": "-aW_lEPn61_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit & Evaluate"
      ],
      "metadata": {
        "id": "9AR3MH6i7xA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MovielensModel(user_model, movie_model)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ],
      "metadata": {
        "id": "FefE_9l-6rZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle, batch, and cache the training & evaluation data\n",
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "metadata": {
        "id": "QuyGmuRR8MeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(cached_train, epochs=3)\n",
        "model.evaluate(cached_test, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9EFjaZ08Wl2",
        "outputId": "350fe833-f981-4b16-e61c-571fb429681e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "10/10 [==============================] - 15s 1s/step - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0013 - factorized_top_k/top_10_categorical_accuracy: 0.0040 - factorized_top_k/top_50_categorical_accuracy: 0.0443 - factorized_top_k/top_100_categorical_accuracy: 0.1070 - loss: 69885.1094 - regularization_loss: 0.0000e+00 - total_loss: 69885.1094\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 10s 1s/step - factorized_top_k/top_1_categorical_accuracy: 9.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0108 - factorized_top_k/top_10_categorical_accuracy: 0.0250 - factorized_top_k/top_50_categorical_accuracy: 0.1404 - factorized_top_k/top_100_categorical_accuracy: 0.2633 - loss: 67523.3693 - regularization_loss: 0.0000e+00 - total_loss: 67523.3693\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 10s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0175 - factorized_top_k/top_10_categorical_accuracy: 0.0387 - factorized_top_k/top_50_categorical_accuracy: 0.1769 - factorized_top_k/top_100_categorical_accuracy: 0.3049 - loss: 66302.9574 - regularization_loss: 0.0000e+00 - total_loss: 66302.9574\n",
            "5/5 [==============================] - 6s 556ms/step - factorized_top_k/top_1_categorical_accuracy: 9.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0094 - factorized_top_k/top_10_categorical_accuracy: 0.0223 - factorized_top_k/top_50_categorical_accuracy: 0.1247 - factorized_top_k/top_100_categorical_accuracy: 0.2328 - loss: 31079.0628 - regularization_loss: 0.0000e+00 - total_loss: 31079.0628\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'factorized_top_k/top_100_categorical_accuracy': 0.23280000686645508,\n",
              " 'factorized_top_k/top_10_categorical_accuracy': 0.022299999371170998,\n",
              " 'factorized_top_k/top_1_categorical_accuracy': 0.0008999999845400453,\n",
              " 'factorized_top_k/top_50_categorical_accuracy': 0.12470000237226486,\n",
              " 'factorized_top_k/top_5_categorical_accuracy': 0.009399999864399433,\n",
              " 'loss': 28244.7734375,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 28244.7734375}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test set에 대한 performance가 training set에 대해서보다 훨씬 안 좋다. 이러한 현상의 이유로는 두 가지 정도를 생각할 수 있다.\n",
        "\n",
        "1. 너무 많은 feature 등의 이유로 모델이 overfitting 되었다. 이는 regularization 혹은 feature engineering을 통해 새로운 데이터에 대한 예측을 돕는 feature를 추가하는 식으로 조절할 수 있다.\n",
        "\n",
        "2. 모델이 items_known을 추천하고 있다. Top-K에 대해서 정확도를 계산하기 때문에 중복 추천이 발생할 경우 test set에서의 performance가 안 좋을 수 있다. 이 경우는 재추천을 허용하지 않음으로써 막을 수 있다."
      ],
      "metadata": {
        "id": "xK_W8zo0BBQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions"
      ],
      "metadata": {
        "id": "0G5ylDiTH_Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model that takes in raw query features, and\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "# recommends movies out of the entire movies dataset.\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DixH5iBASE7",
        "outputId": "cf2d5c97-35e9-4c7a-f8f7-7c67acc0fd04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7fa5c421fd50>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get recommendations.\n",
        "_, titles = index(tf.constant([\"42\"]))\n",
        "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuKQJoGlIEaP",
        "outputId": "9576cc07-939d-442c-e4e5-5887d07ec698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user 42: [b'Bridges of Madison County, The (1995)'\n",
            " b'Father of the Bride Part II (1995)' b'Rudy (1993)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`BruteForce` layer는 많은 후보군을 가지는 경우 모델 서빙을 느리게 만든다. 따라서, 적절한 retrieval index를 이용해 이를 빠르게 만드는 방법에 대해 알아보자."
      ],
      "metadata": {
        "id": "MggUofk1IKzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Serving"
      ],
      "metadata": {
        "id": "6fcOpgOMIcY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습이 완료된 후, 우리는 이것을 배포하는 방법이 필요하다.\n",
        "\n",
        "위와 같은 Two-tower Retrieval model의 경우, 서빙에는 다음과 같은 두 개의 components가 포함된다.\n",
        "\n",
        "1. query의 feature를 받아 query embedding으로 만드는 query model의 서빙\n",
        "2. query model의 결과로 나온 query에 대하여 후보군을 빠르게 찾는 ANN 모델의 인덱스를 받아 후보군을 생성하는 candidate model의 서빙"
      ],
      "metadata": {
        "id": "bHXZ5MRYIgJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the query model.\n",
        "with tempfile.TemporaryDirectory() as tmp:\n",
        "  path = os.path.join(tmp, \"model\")\n",
        "\n",
        "  # Save the index.\n",
        "  tf.saved_model.save(index, path)\n",
        "\n",
        "  # Load it back; can also be done in TensorFlow Serving.\n",
        "  loaded = tf.saved_model.load(path)\n",
        "\n",
        "  # Pass a user id in, get top predicted movie titles back.\n",
        "  scores, titles = loaded([\"42\"])\n",
        "\n",
        "  print(f\"Recommendations: {titles[0][:3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oYgOYmVIGoj",
        "outputId": "2c217827-456f-4d09-e123-11b6a09269b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpzcqbd36r/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpzcqbd36r/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations: [b'Bridges of Madison County, The (1995)'\n",
            " b'Father of the Bride Part II (1995)' b'Rudy (1993)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "또한 우리는 예측의 속도를 높이기 위해 적절한 retrieval index를 export할 수도 있는데, 이는 수많은 후보군에 대해 빠르게 예측을 수행할 수 있도록 한다."
      ],
      "metadata": {
        "id": "KN9kfKsyJqg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scann_index = tfrs.layers.factorized_top_k.ScaNN(model.user_model)\n",
        "scann_index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLE46w29Ji75",
        "outputId": "be243eab-d230-4f92-9ef7-67b1ec32bce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7fa5c3f96ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get recommendations.\n",
        "_, titles = scann_index(tf.constant([\"42\"]))\n",
        "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZztkcKFJ-6K",
        "outputId": "43e3f62d-d9c1-4e9f-ef20-73100f89ce49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user 42: [b'Sleepless in Seattle (1993)' b'Father of the Bride Part II (1995)'\n",
            " b'Hunchback of Notre Dame, The (1996)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the query model.\n",
        "with tempfile.TemporaryDirectory() as tmp:\n",
        "  path = os.path.join(tmp, \"model\")\n",
        "\n",
        "  # Save the index.\n",
        "  tf.saved_model.save(\n",
        "      index,\n",
        "      path,\n",
        "      options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",
        "  )\n",
        "\n",
        "  # Load it back; can also be done in TensorFlow Serving.\n",
        "  loaded = tf.saved_model.load(path)\n",
        "\n",
        "  # Pass a user id in, get top predicted movie titles back.\n",
        "  scores, titles = loaded([\"42\"])\n",
        "\n",
        "  print(f\"Recommendations: {titles[0][:3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyoC2LZqKAWD",
        "outputId": "6361ab19-d0c0-4842-f67b-353374c709e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9tcyzpad/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9tcyzpad/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations: [b'Bridges of Madison County, The (1995)'\n",
            " b'Father of the Bride Part II (1995)' b'Rudy (1993)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To learn more about using and tuning fast approximate retrieval models, have a look at [efficient serving](https://tensorflow.org/recommenders/examples/efficient_serving) tutorial."
      ],
      "metadata": {
        "id": "JdKT4A9ZKHLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### +) Item-to-Item recommendation\n",
        "\n",
        "여기서, 우리는 user-movie model을 만들었다. 하지만, 일부 상황에서는 item-item model이 필요한 경우 또한 존재한다.\n",
        "\n",
        "이러한 모델은 전반적인 과정이 위와 동일하나 다른 데이터를 사용해야한다. 여기서는 user와 movie tower를 통해 (유저, 영화) 쌍을 학습에 이용했지만 item-item model에서는 두 개의 item tower를 이용해야 할 것이다. \n",
        "\n",
        "데이터 예시: 물품 상세보기 페이지 클릭"
      ],
      "metadata": {
        "id": "4qhsDA10KTPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Ranking Model"
      ],
      "metadata": {
        "id": "NyZD8_qqggGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 구현한 Retrieval Model의 결과값으로 나온 후보군에 대하여 랭킹을 계산하고 이를 통해 최종 추천 항목을 구하는 모델이다."
      ],
      "metadata": {
        "id": "koosi4fBgtWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Packages\n"
      ],
      "metadata": {
        "id": "Nv-KLwuvhARf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 진행한 부분이지만, 추후 이 부분만을 다시 돌릴 수 있도록 처음부터 진행하겠다."
      ],
      "metadata": {
        "id": "UFdcfgZZhN09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ],
      "metadata": {
        "id": "j1YXVKVTKCOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs"
      ],
      "metadata": {
        "id": "Ejzu-PwThVO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Dataset"
      ],
      "metadata": {
        "id": "cbGdbRtbhbYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"user_rating\": x[\"user_rating\"]\n",
        "})"
      ],
      "metadata": {
        "id": "1zngOWyqhYn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieval에서와 같은 데이터를 사용한다. 차이점은, Retrieval 모델에서 단순히 유저와 영화만의 관계를 이용했다면, 여기서는 해당 유저가 영화에 준 rating 값 또한 학습에 이용하도록 하겠다. "
      ],
      "metadata": {
        "id": "GnZonF_YhijL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)"
      ],
      "metadata": {
        "id": "dkIAPt9ahgO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_titles = ratings.batch(1_000_000).map(lambda x: x[\"movie_title\"])\n",
        "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
        "\n",
        "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
      ],
      "metadata": {
        "id": "PucLxTY2h0B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing a Model"
      ],
      "metadata": {
        "id": "HCjfj56DjE_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "AUuig0DPjVBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ranking Model은 Retrieval Model과 달리 efficiency constraints를 지킬 필요가 없다.\n",
        "\n",
        "모델은 다중 stacked dense layer로 이루어져있고, 이는 Ranking에 사용되는 공통된 아키텍쳐를 가진다."
      ],
      "metadata": {
        "id": "yR29QVlKjYmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RankingModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    embedding_dimension = 32\n",
        "\n",
        "    # Compute embeddings for users.\n",
        "    self.user_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_user_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # Compute embeddings for movies.\n",
        "    self.movie_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_movie_titles, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # Compute predictions.\n",
        "    self.ratings = tf.keras.Sequential([\n",
        "      # Learn multiple dense layers.\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "      # Make rating predictions in the final layer.\n",
        "      tf.keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    user_id, movie_title = inputs\n",
        "\n",
        "    user_embedding = self.user_embeddings(user_id)\n",
        "    movie_embedding = self.movie_embeddings(movie_title)\n",
        "\n",
        "    return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
      ],
      "metadata": {
        "id": "gdhc0g40jDyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`RankingModel`은 유저 아이디와 영화 제목을 받아 예측 평점을 출력한다."
      ],
      "metadata": {
        "id": "02vfAxvlkOmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RankingModel()(([\"42\"], [\"Bridges of Madison County, The (1995)\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aemEI4QgkM_F",
        "outputId": "a6e20606-15e7-49fe-a597-4b49ca12634f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['42']\n",
            "Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['42']\n",
            "Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['Bridges of Madison County, The (1995)']\n",
            "Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['Bridges of Madison County, The (1995)']\n",
            "Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.0076181]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss and Metrics"
      ],
      "metadata": {
        "id": "eud82Bm1llez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFRS에서 Ranking Task를 위해 제공하는 Loss와 Metric object를 사용하겠다."
      ],
      "metadata": {
        "id": "yuvNoh3TlqYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = tfrs.tasks.Ranking(\n",
        "  loss = tf.keras.losses.MeanSquaredError(),\n",
        "  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ],
      "metadata": {
        "id": "xXmBY11KkWEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 태스크는 그 자체로 하나의 Keras layer이고, 실제 값과 예측 값은 인자로 받아 loss를 출력한다."
      ],
      "metadata": {
        "id": "6wKg8E2Yl5zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Full Model"
      ],
      "metadata": {
        "id": "LNkqFLqsmC7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MovielensModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ranking_model: tf.keras.Model = RankingModel()\n",
        "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "      loss = tf.keras.losses.MeanSquaredError(),\n",
        "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "\n",
        "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "    return self.ranking_model(\n",
        "        (features[\"user_id\"], features[\"movie_title\"]))\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    labels = features.pop(\"user_rating\")\n",
        "\n",
        "    rating_predictions = self(features)\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(labels=labels, predictions=rating_predictions)"
      ],
      "metadata": {
        "id": "OFueZs2Il1gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting and Evaluating"
      ],
      "metadata": {
        "id": "HW6yrg4mmJ_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MovielensModel()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ],
      "metadata": {
        "id": "1rNhUTfkmF_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "metadata": {
        "id": "MiHSrQOimNd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(cached_train, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gjpb29QmOyZ",
        "outputId": "d50a47d0-bed7-433a-f2b2-b17eb52e4cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "10/10 [==============================] - 4s 28ms/step - root_mean_squared_error: 2.0840 - loss: 3.9935 - regularization_loss: 0.0000e+00 - total_loss: 3.9935\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 14ms/step - root_mean_squared_error: 1.1253 - loss: 1.2617 - regularization_loss: 0.0000e+00 - total_loss: 1.2617\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 12ms/step - root_mean_squared_error: 1.1178 - loss: 1.2437 - regularization_loss: 0.0000e+00 - total_loss: 1.2437\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa544fde3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습이 진행될 수록 loss가 떨어지는 것을 확인할 수 있다.\n",
        "\n",
        "마지막으로 test set에 대해 evaluate 해보자."
      ],
      "metadata": {
        "id": "iUtmato0mUcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(cached_test, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsDYmoLcmQRj",
        "outputId": "85a9b513-4818-4aa7-cb3a-8d757d694b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 3s 15ms/step - root_mean_squared_error: 1.1086 - loss: 1.2241 - regularization_loss: 0.0000e+00 - total_loss: 1.2241\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 1.2020609378814697,\n",
              " 'regularization_loss': 0,\n",
              " 'root_mean_squared_error': 1.1086448431015015,\n",
              " 'total_loss': 1.2020609378814697}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the Ranking Model"
      ],
      "metadata": {
        "id": "ogmrVtV0mgnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ratings = {}\n",
        "test_movie_titles = [\"M*A*S*H (1970)\", \"Dances with Wolves (1990)\", \"Speed (1994)\"]\n",
        "for movie_title in test_movie_titles:\n",
        "  test_ratings[movie_title] = model({\n",
        "      \"user_id\": np.array([\"42\"]),\n",
        "      \"movie_title\": np.array([movie_title])\n",
        "  })\n",
        "\n",
        "print(\"Ratings:\")\n",
        "for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "  print(f\"{title}: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yyif-oxjmdcQ",
        "outputId": "bfe4c05e-dd84-481b-f044-3d9a404d8b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings:\n",
            "Dances with Wolves (1990): [[3.6997178]]\n",
            "M*A*S*H (1970): [[3.6699927]]\n",
            "Speed (1994): [[3.6349838]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exporting for Serving"
      ],
      "metadata": {
        "id": "1SjS4sBNmmWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델은 serving을 통해 쉽게 export될 수 있다."
      ],
      "metadata": {
        "id": "Qi_-UNgBmpj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, \"export\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I31Q8Gr-mkQL",
        "outputId": "897aeda7-c681-4b16-dba8-c3d26e8a1e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as ranking_1_layer_call_fn, ranking_1_layer_call_and_return_conditional_losses, ranking_1_layer_call_fn, ranking_1_layer_call_and_return_conditional_losses, ranking_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: export/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: export/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded = tf.saved_model.load(\"export\")\n",
        "\n",
        "loaded({\"user_id\": np.array([\"42\"]), \"movie_title\": [\"Speed (1994)\"]}).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FJgk_nYmtRB",
        "outputId": "e3b662d3-50ba-4bc8-9e80-1a33991bbfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.6349838]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrap-up\n"
      ],
      "metadata": {
        "id": "LUhGUswenPCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이로써 기본적인 Retrieval Model과 Ranking Model의 구축이 끝났다.\n",
        "\n",
        "물론 이것은 굉장히 간단한 모델이고, 실무에서 사용되는 모델은 이보다 훨씬 복잡할 것이다.\n",
        "대부분의 경우에 Ranking Model은 여기서와 달리 유저-아이템의 identifier 외에도 많은 feature를 사용하여 Ranking을 계산한다. 이에 대해서는 TensorFlow_Recommender_Using_Rich_Features에서 다룰 것이다.\n",
        "\n",
        "또한 objective worth optimizing에 대한 이해가 필요한데, 이는 TensorFlow_Recommender_Multitask에서 다루도록 하겠다."
      ],
      "metadata": {
        "id": "mVaH3CK1nSxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O-3K---Pmvil"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}