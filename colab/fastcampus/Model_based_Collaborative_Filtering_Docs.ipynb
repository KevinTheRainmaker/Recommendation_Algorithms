{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model-based_Collaborative_Filtering_Docs.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IVSFYhxnPHpz",
        "ApCMxnuf2CIh"
      ],
      "authorship_tag": "ABX9TyNhuZhjGCzPYdrqyMx6AHJs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinTheRainmaker/Recommendation_Algorithms/blob/main/colab/fastcampus/Model_based_Collaborative_Filtering_Docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGsczgzmLZrG"
      },
      "source": [
        "# 모델기반 협업필터링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yolSIvzOzfM"
      },
      "source": [
        "## 1. 모델기반 협업필터링이란\n",
        "\n",
        "- 머신러닝과 그 특징을 가장 잘 활용한 추천 알고리즘의 일종\n",
        "- 주어진 데이터를 활용하여 모델 학습\n",
        "  - 학습과정에서 모델이 데이터를 배워서 데이터 정보를 압축\n",
        "\n",
        "- 항목간 유사성에서 벗어나, 데이터의 패턴을 학습\n",
        "- 데이터 크기 또는 데이터의 feature를 동적으로 활용 가능\n",
        "- 데이터(유저)의 잠재적 특성(선호 취향)을 파악하는 모델 (Latent Factor Model)\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 장점\n",
        "- 추천모델의 크기가 작다\n",
        "  - 수많은 데이터로 구성된 행렬(ex. Rating Matrix)보다 압축된 형태로 저장\n",
        "- 추천모델의 학습과 예측 속도가 빠르다\n",
        "  - 데이터 전처리와 학습과정으로 미리 모델을 준비하여, 준비된 모델로 예측\n",
        "- 추천모델의 과적합 방지\n",
        "  - 데이터를 다양하게 학습할 수 있고, 새로운 추천을 할 가능성이 있음\n",
        "- Sparse data에 대하여 적용이 가능\n",
        "- Limited Coverage 문제(유저 혹은 아이템 간 교집합이 적은 문제) 해결 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yixiKlS0OvdQ"
      },
      "source": [
        "## 2. 모델기반 협업필터링 종류\n",
        "\n",
        "- Association Rule Mining\n",
        "- Matrix Factorization\n",
        "  - SVD(Singular Value Decomposition), ALS(Alternating Least Square)\n",
        "- Probabilistic Models\n",
        "  - Clustering, Bayes Rules\n",
        "- Etc.\n",
        "  - SVM, Regression methods(Logistic Regression), Deep Learning...\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVSFYhxnPHpz"
      },
      "source": [
        "### 2-1. Association Rule Mining (feat. Rule-based CF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEu_OPDR2Oru"
      },
      "source": [
        "- 데이터의 모델 \n",
        "> 데이터 간 관계, 접근과 흐름 파악을 위한 추상화된 모형\n",
        "\n",
        "- 데이터 간의 연관 법칙을 찾는 data mining 기법 중 하나로, 데이터의 여러 특징을 파악해서 모델링\n",
        "\n",
        "- 기존 데이터를 기반으로 Association Rule(연관 규칙)을 만든다\n",
        "\n",
        "- 이산형 변수로의 데이터 Profiling 통해 Association Rule 적용 가능\n",
        "  - Profile Association Rule\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 정의\n",
        "- Minimum Support와 Minimum Confidence 값을 넘는 Rule을 찾는 과정\n",
        "- 데이터에서 흥미로운 관계를 찾는 Rule-based ML 기법 중 하나\n",
        "- 특정 measure를 통해 interestingness를 평가하여 Strong Rule을 찾는 과정\n",
        "\n",
        "1) Support(지지도)\n",
        "- 데이터 관계 설정을 위해 아이템이 동시에 발생할 확률\n",
        "- 전체 데이터 중 규칙 (A,B)를 포함하는 데이터 비율\n",
        "\n",
        "\n",
        "2) Confidence(신뢰도)\n",
        "- 특정 아이템 A가 선택된 상태에서 다른 아이템 B를 선택할 확률\n",
        "- (A,B)의 관계를 가정하고, A를 선택한 사람이 B를 선택한 비율\n",
        "\n",
        "3) Lift(향상도)\n",
        "- (A,B)의 관계를 직접적으로 나타내는 measurement\n",
        "- 1보다 크면, 이어서 B를 선택할 확률이 높고, 1보다 작다면 확률이 낮다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soiJRKrlS4TA"
      },
      "source": [
        "#### 1) Support\n",
        "$support(A \\rightarrow B) = {\\# \\ of \\ (A \\cap B) \\over \\# \\ of \\ data(rows)} = P(A\\cap B)$\n",
        "\n",
        "- 0~1 사이 값\n",
        "- 1에 가까울수록 A와 B 관계가 중요하다는 것을 의미\n",
        "- 0에 가까운 연관관계를 먼저 제거 $\\rightarrow$ 자주 발생하지 않음을 의미\n",
        "- 단점) $support(A \\rightarrow B)$ 와 $support(B \\rightarrow A)$ 차이 파악 불가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsCxi03AUtk_"
      },
      "source": [
        "#### 2) Confidence\n",
        "$confidence(A\\rightarrow B) = {\\# \\ of \\ (A\\cap B)\\over \\# \\ of \\ A} = {P(A\\cap B)\\over P(A)}$\n",
        "\n",
        "- 0~1 사이 값\n",
        "- A를 선택했을 때, B를 선택할 확률 $\\rightarrow$ $confidence(A \\rightarrow B)$ 와 $confidence(B \\rightarrow A)$ 차이 파악 가능\n",
        "- 1에 가까울수록 A는 B에 많은 영향을 받음 $\\rightarrow$ minimum support 중 가장 큰 confidence 선택"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRN6R1O1V1iK"
      },
      "source": [
        "#### 3) Lift\n",
        "$lift(A\\rightarrow B) = {confidence(A\\rightarrow B)\\over support(B)} = {P(A\\cap B)\\over P(A)\\ * \\ P(B)}$\n",
        "\n",
        "- 0~1 사이 확률값이 아닌 A와 B사이의 관계를 파악하는 용도로 사용\n",
        "- $lift(A\\rightarrow B) < 1$: 상호대체 $\\rightarrow$ A와 B는 반비례\n",
        "- $lift(A\\rightarrow B) > 1$: 상호보완 $\\rightarrow$ A와 B는 정비례\n",
        "- $lift(A\\rightarrow B) = 1$: 독립 $\\rightarrow$ A와 B는 서로에게 영향을 끼치지 않음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApCMxnuf2CIh"
      },
      "source": [
        "### 2-2. Latent Factor Model (feat. Matrix Factorization)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89BDeORS2SDk"
      },
      "source": [
        "- 사용자/아이템 특성을 벡터로 간략화(요약)하는 모델링\n",
        "\n",
        "- 사용자/아이템 특성 간 복잡한 관계를 학습한다\n",
        "\n",
        "- 사용자/아이템 행렬에서 사용자와 아이템을 factor로 나타내는 방법\n",
        "\n",
        "- **사용자와 아이템이 같은 vector 공간에 표현된다**\n",
        "\n",
        "- 사용자와 아이템을 모르는 차원(dimension)에 표현하는데, 이때 차원의 수는 알 수 없다\n",
        "\n",
        "- 같은 vector 공간에서 사용자와 아이템이 가까우면 유사, 멀리 떨어져 있으면 유사하지 않다고 판단한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SDFUG4a3vvW"
      },
      "source": [
        "#### Singular Value Decomposition\n",
        "\n",
        "- 차원 축소 기법 (Dimensionality Reduction) 중 하나\n",
        "  - 노이즈 제거, Sparse matrix 형태로 큰 데이터 축소\n",
        "  - 참고: PCA(Principle Component Analysis)\n",
        "- 사용자와 아이템 간 데이터를 행렬 R로 나타낸다.\n",
        "\n",
        "  $A = U\\Sigma V^T$\n",
        "\n",
        "- $U$는 고유값 분해(SVD)로 얻은 m x m 직교 행렬\n",
        "  - $AA^T = U(\\Sigma \\Sigma^T)U^T$\n",
        "  - $U$의 열벡터는 $A$의 left singular vector\n",
        "\n",
        "- $V$는 고유값 분해로 얻은 n x n 직교 행렬\n",
        "  - $A^TA = V(\\Sigma^T\\Sigma)V^T$\n",
        "  - $V$의 열벡터는 $A$의 right singular vector\n",
        "\n",
        "- $\\Sigma$는 m x n 대각행렬\n",
        "  - 고유값 분해해서 나온 eigenvalue의 제곱근이 대각성분\n",
        "  - 대각성분 = $A$의 특이값\n",
        "  - latent factor의 중요도\n",
        "\n",
        "- 행렬 $U$는 사용자와 latent factor, $V$는 아이템과 latent factor간의 관계를 나타낸다\n",
        "  - 사용자와 아이템의 관계를 2차원 직교좌표계로 표현한다 \n",
        "    - 사용자와 아이템의 고유값 계산 $\\rightarrow$ 고유값으로 기존 평점데이터를 다시 계산\n",
        "\n",
        "- 행렬 $U$와 $V$의 모든 열벡터는 특이벡터(singular vector)\n",
        "  \n",
        "  모든 특이벡터는 서로 직교한다\n",
        "\n",
        "  $U^TU = I,\\ V^TV = I$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erql85yiCQTC"
      },
      "source": [
        "#### Matrix Factorization\n",
        "\n",
        "- Latent Factor Model을 구현하는 방법\n",
        "- Rating Matrix를 분해하는 과정\n",
        "- $|U|X|I|$: user-item rating matrix (rank k < n)\n",
        "- $P \\rightarrow |U|Xk$: matrix of user factors\n",
        "- $Q \\rightarrow |I|Xk$: matrix of item factors\n",
        "- 분해한 행렬 P와 Q를 곱하여 평점을 예측한다\n",
        "- 임의의 차원 수 k는 직접 정한다\n",
        "- $R_{ui} = P^T_u X Q_i$\n",
        "- $R$(원본 rating matrix)과 $R'$(예측 matrix)이 서로 유사하도록 학습하는 과정\n",
        "  - 관측된 data만 사용\n",
        "  - (true rating - predicted rating)으로 근사값을 추론하는 문제\n",
        "  -  user u가 item i에 대해 줄 예측 rating 값 (predicted rating) = $\\hat {R_{ui}} = P^T_u X Q_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vlk7DLfkOYzL"
      },
      "source": [
        "#### Objective Function of MF\n",
        "\n",
        "  $min \\Sigma_{(u,i)\\in Training} (R_{ui} - P^T_uQ_i)^2 + \\lambda(||P_u||^2 + ||Q_i||^2)$\n",
        "\n",
        "- $\\lambda(||P_u||^2 + ||Q_i||^2)$: 정규화 (regularization) - Overfitting을 피하기 위한 error term"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH1mw0RpJABW"
      },
      "source": [
        "#### Stochastic Gradient Descent\n",
        "\n",
        "- 학습 데이터의 모든 rating을 훑는 방법\n",
        "- 실제 평점과 예측 평점의 차이를 Error term으로 정의\n",
        "  - $e_{ui} = R_{ui} - P^T_uQ_i$\n",
        "- Gradient 반대 방향으로 $P^T_u$와 $Q_i$을 update\n",
        "  - $P_u \\leftarrow P_u + \\gamma(e_{ui} * Q_i - \\lambda * P_u)$\n",
        "  - $Q_i \\leftarrow Q_i + \\gamma(e_{ui} * P_u - \\lambda * Q_i)$\n",
        "- 구현이 쉽고 계산이 빠르다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IdXwu7dSmY4"
      },
      "source": [
        "#### Alternating Least Squares\n",
        "\n",
        "- 일반적으로 $P_u$와 $Q_i$를 모두 알 수는 없는 경우가 대다수\n",
        "  - loss function이 non-convex(=최적해를 빠르고 정확하게 찾기 힘들다)\n",
        "- $P_u$와 $Q_i$ 중 한 쪽을 고정하고 식을 quadratic equation으로 하여 최적화 문제 해결\n",
        "- $P_u$와 $Q_i$를 번갈아 고정시키면서, least-square(최소제곱) 문제를 풀게 된다\n",
        "  - $P_u$와 $Q_i$를 독립적으로 계산하기 때문에 병렬처리에 사용할 수 있다\n",
        "- Implicit feedback 처리 시 유용 (Explicit에 비해 dense하여 연산량 $\\uparrow$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKDPQDGGnFRl"
      },
      "source": [
        "#### More on Matrix Factorization\n",
        "\n",
        "- Matrix Completion 문제로, 다양한 SVD 기법을 통해 행렬 분해를 수행하여 특이값을 도출한다.\n",
        "- loss function을 최적화하기 위해 SGD, ALS 등의 Optimization을 이용\n",
        "- 정보를 추가하여 모델링 할 수 있다\n",
        "  - Explicit과 Implicit feedback을 Matrix Factorization에 녹여낸다\n",
        "\n",
        "- Adding Bias: User u와 Item i의 개별 특성을 함께 표현하기 위해 bias term 추가\n",
        "\n",
        "  $\\hat{r_{ui}} = \\mu + bias_i + bias_u + P^T_uQ_i$\n",
        "    - $\\mu$: 모든 item의 평균(모든 평점 평균)\n",
        "    - $bias_i$: 전체 item 평균에 대한 item i의 편차(deviation)\n",
        "    - $bias_u$: 전체 user 평균에 대한 user u의 편차(deviation)\n",
        "\n",
        "- Additional Input Sources\n",
        "  - Behavior Information 등 추가 정보를 활용한 모델링 가능\n",
        "  - $\\Sigma_{i\\in N(u)}Q_i$: User u의 Item i에 대한 implicit feedback\n",
        "    - $N(u)$: 전체 Item에 대한 User u의 implicit feedback\n",
        "  - $\\Sigma_{a\\in A(a)}P_a$: User u의 Personal or non-item related information\n",
        "    - 성별, 나이, 주소 등 Context data\n",
        "  \n",
        "  $\\hat{r_{ui}} = \\mu + bias_i + bias_u + P^T_u[Q_i + |N(u]|^{-0.5} \\Sigma_{i\\in N(u)}Q_i * \\Sigma_{a\\in A(a)}P_a]$\n",
        "\n",
        "- Temporal Dynamics\n",
        "  - 데이터를 시간의 변화에 따라 동적으로 반영하는 모델링\n",
        "  - t는 시간의 변화를 표현\n",
        "  - item i의 인기도가 시간이 흐름에 따라 변하는 경우\n",
        "  \n",
        "  $\\hat{ r_{ui}(t) } = \\mu + bias_i(t) + bias_u(t) + P^T_iQ_u(t)$\n",
        "\n",
        "- Inputs with Varying Confidence Levels\n",
        "  - 데이터가 동일한 가중치 또는 신뢰도가 아닌 상황을 모델링\n",
        "  - 대규모 광고에 영향을 받은 item이 자주 선택되는 경우\n",
        "  - Implicit feedback 데이터에서 user가 실제로 선호하는지 판단하기 어려운 경우\n",
        "\n",
        "    $min \\Sigma_{(u,i)\\in Train} c_{ui}(r_{ui} - \\mu - bias_i - bias_u - P^T_uQ_i)^2 + \\lambda(||P_u||^2 + ||Q_i||^2 + bias_i^2 + ias_u^2)$\n",
        "      - $c_{ui}$: $r_{ui}$에 대한 신뢰도 (또는 가중치)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYRsHVQjxeK9"
      },
      "source": [
        "### 2-3. Advanced Matrix Factorization (feat. Bayesian Personalized Ranking)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnIXOwTDxoSG"
      },
      "source": [
        "- 참고 논문: [BPR: Bayesian Personalized Ranking from Implicit Feedback](https://arxiv.org/abs/1205.2618)\n",
        "\n",
        "  - Implicit Feedback으로 추천알고리즘을 다루는 논문\n",
        "  - Matrix Factorization과 (adaptive) k-NN으로 personalized ranking 실험\n",
        "  - Bayesian을 활용한 최적화 기법(BPR-Opt) 제시: Maximum Posterior Estimator에 기반\n",
        "    - BPR-Opt 위한 학습 알고리즘인 LearnBPR 제안: 기존 SGD보다 우수한 성능\n",
        "  - 위 최적화 기법을 적용하여 기존 방식 대비 우수성 입증\n",
        "  - Implicit feedback으로 ranking을 추천할 수 있는 알고리즘 제시"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zROzTj45IGf"
      },
      "source": [
        "#### Personalized Ranking\n",
        "\n",
        "- User에게 ranked list of ites를 추천하는 것\n",
        "- Item Recommendation이라고도 함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkTiZRZL5kXT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV5vWnQ7VcVn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}